# -*- coding: utf-8 -*-
"""movie recommender tutorial

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hLznsDTe908NNGV0tohIuI8NWEJOhLHr

Reference: https://www.youtube.com/watch?v=eyEabQRBMQA
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

#read in movies dataset
movies = pd.read_csv("ml-25m/movies.csv")
"""`movies` is a dataset of 62423 movies"""

"""# Cleaning movie titles"""
import re #regex library

#we remove special characters in movie names (e.g. ()-:),
#   to make searching by movie name easier
def clean_title(title):
    #search through each title, and look for any characters that
    #   aren't a whitespace, a-z, A-Z, or 0-9, and remove those
    #   characters
    cleaned =  re.sub("[^a-zA-Z0-9 Ã©]", "", title)
    #also remove the year from the cleaned title (works better when searching for movie on TMDB)
    cleaned = re.sub("\d{4}\Z", "", cleaned)
    return cleaned

# Add a new column for the clean title.
#   `apply` method will apply clean_title fcn to every title in the "title" column
movies["clean_title"] = movies["title"].apply(clean_title)

"""View the new cleaned titles:"""
#print(movies.head)


"""# Build the search engine
## Create a tfidf matrix (term frequency matrix)
Convert each title into a vector, so we can compare the similarity between the movie titles.
"""
#ngram_range=(1,2) tells the vectorizer to look at groups of 2 consecutive words (ngrams)
#   e.g. for the title "Toy Story 1995", the ngrams are "Toy Story", "Story 1995"
vectorizer = TfidfVectorizer(ngram_range=(1,2))

#now use the vectorizer to transform the clean titles into matrices
tfidf = vectorizer.fit_transform(movies["clean_title"])

"""Now compute the similarity b/t the search term and each movie title in the movies list. Use cosine similarity."""
def search(title):
  title = clean_title(title)
  query_vec = vectorizer.transform([title])
  similarity = cosine_similarity(query_vec, tfidf).flatten()
  indices = np.argpartition(similarity, -5)[-5:]
  results = movies.iloc[indices][::-1]
  return results



"""# Part 2: Building the recommendation system
## Read in ratings.csv
We will find movies that are similar to movies we like, using user ratings.
"""
ratings = pd.read_csv("ml-25m/ratings.csv")

"""Find all the users who also liked the movie we are searching for. 
Then find the other movies they liked. These will be our recommendations"""


def find_similar_movies(movie_id):
  #find all the UNIQUE users who also watched the query movie, AND liked it (rated it >4 stars)
  similar_users = ratings[(ratings["movieId"] == movie_id) & (ratings["rating"]> 4)]["userId"].unique()
  #get all the movies watched by the these similar users
  similar_user_recs = ratings[(ratings["userId"].isin(similar_users)) & (ratings["rating"]> 4)]["movieId"]

  #get the movies in similar_users where > 10% of similar_users liked the movie
  similar_user_recs = similar_user_recs.value_counts()/len(similar_users) #convert # of times each movie was watched into a percentage out of all the users
  similar_user_recs = similar_user_recs[similar_user_recs > 0.1]

  #get the percentage of all_users who watched the query movie AND liked it (rated >4), for each movie in similar_user_recs
  all_users = ratings[(ratings["movieId"].isin(similar_user_recs.index) & (ratings["rating"]>4))]
  all_users_recs = all_users["movieId"].value_counts() / len(all_users["userId"].unique())

   # create a new dataframe to compare percentages of how much each movie was liked, b/t similar_users and all_users
  rec_percentages = pd.concat([similar_user_recs, all_users_recs], axis=1)
  rec_percentages.columns = ["similar", "all"]

  #find the ratios b/t percentages
  rec_percentages["score"] = rec_percentages["similar"] / rec_percentages["all"]

  #sort percentages by largest to smallest similar/all ratio (i.e. "score")
  rec_percentages = rec_percentages.sort_values("score", ascending = False)
  #merge this dataset on the right with the movieID from the movies dataset
  return rec_percentages.head(10).merge(movies, left_index=True, right_on="movieId")[["score", "title", "clean_title", "genres"]]
